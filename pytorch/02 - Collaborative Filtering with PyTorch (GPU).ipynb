{"cells": [{"metadata": {"ExecuteTime": {"start_time": "2018-06-16T22:53:30.289199Z", "end_time": "2018-06-16T22:53:30.294772Z"}}, "cell_type": "markdown", "source": "**Purpose of this notebook**\n\nImplement collaborative filtering on movielens dataset\n1. Matrix Factorization\n2. Using Neural Network to learn embeddings"}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:30.283231Z", "end_time": "2018-06-16T23:37:30.291672Z"}, "trusted": true}, "cell_type": "code", "source": "from pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport zipfile\nfrom tqdm import tnrange, tqdm", "execution_count": 53, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:05:20.972055Z", "end_time": "2018-06-16T23:05:20.975057Z"}, "trusted": true}, "cell_type": "code", "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F", "execution_count": 19, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T22:56:05.740710Z", "end_time": "2018-06-16T22:56:05.743451Z"}, "trusted": true}, "cell_type": "code", "source": "PATH = Path('data/')", "execution_count": 3, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:03:03.904168Z", "end_time": "2018-06-16T23:03:03.961527Z"}, "trusted": true}, "cell_type": "code", "source": "with zipfile.ZipFile(PATH/'ml-latest-small.zip') as z:\n    with z.open('ml-latest-small/ratings.csv') as f:\n        data = pd.read_csv(f)", "execution_count": 13, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:03:04.113935Z", "end_time": "2018-06-16T23:03:04.122453Z"}, "trusted": true}, "cell_type": "code", "source": "data.head()", "execution_count": 14, "outputs": [{"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "   userId  movieId  rating   timestamp\n0       1       31     2.5  1260759144\n1       1     1029     3.0  1260759179\n2       1     1061     3.0  1260759182\n3       1     1129     2.0  1260759185\n4       1     1172     4.0  1260759205", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>31</td>\n      <td>2.5</td>\n      <td>1260759144</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1029</td>\n      <td>3.0</td>\n      <td>1260759179</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1061</td>\n      <td>3.0</td>\n      <td>1260759182</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1129</td>\n      <td>2.0</td>\n      <td>1260759185</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1172</td>\n      <td>4.0</td>\n      <td>1260759205</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Encode Data"}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:03:06.488504Z", "end_time": "2018-06-16T23:03:06.500240Z"}, "trusted": true}, "cell_type": "code", "source": "# split train and validation before encoding\nnp.random.seed(3)\nmsk = np.random.rand(len(data)) < 0.8\ntrain = data[msk].copy()\nval = data[~msk].copy()", "execution_count": 15, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:03:20.741303Z", "end_time": "2018-06-16T23:03:20.746419Z"}, "trusted": true}, "cell_type": "code", "source": "def proc_col(col, train_col=None):\n    \"\"\"\n    Encodes a pandas column with continous ids. \n    \"\"\"\n    if train_col is not None:\n        uniq = train_col.unique()\n    else:\n        uniq = col.unique()\n    name2idx = {o:i for i,o in enumerate(uniq)}\n    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)", "execution_count": 16, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:03:32.164214Z", "end_time": "2018-06-16T23:03:32.168155Z"}, "trusted": true}, "cell_type": "code", "source": "def encode_data(df, train=None):\n    \"\"\"\n    Encodes rating data with continous user and movie ids. \n    If train is provided, encodes df with the same encoding as train.\n    \"\"\"\n    df = df.copy()\n    for col_name in [\"userId\", \"movieId\"]:\n        train_col = None\n        if train is not None:\n            train_col = train[col_name]\n        _,col,_ = proc_col(df[col_name], train_col)\n        df[col_name] = col\n        df = df[df[col_name] >= 0]\n    return df", "execution_count": 17, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:04:30.674813Z", "end_time": "2018-06-16T23:04:30.774604Z"}, "trusted": true}, "cell_type": "code", "source": "df_train = encode_data(train)\ndf_val = encode_data(val, train)", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Embeddings Layer"}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:06:31.796436Z", "end_time": "2018-06-16T23:06:31.805791Z"}, "trusted": true}, "cell_type": "code", "source": "# an Embedding object containing 10 users or items embedding size 3\n# embeddings will be initialized at random\nembed = nn.Embedding(10, 3)\nembed.weight", "execution_count": 20, "outputs": [{"output_type": "execute_result", "execution_count": 20, "data": {"text/plain": "Parameter containing:\ntensor([[-0.0596,  0.6845,  0.8395],\n        [ 0.1271, -0.2549,  0.3582],\n        [-0.7586,  0.0949,  1.0023],\n        [-1.4211, -0.6909, -0.0179],\n        [ 1.0334,  1.7368,  0.4366],\n        [-0.8050,  0.0520,  0.0131],\n        [ 0.4518,  0.2676, -0.1353],\n        [-0.5609,  2.3864, -1.0803],\n        [ 1.6733,  0.4910,  0.5521],\n        [ 0.1019, -0.3812, -0.5394]])"}, "metadata": {}}]}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:07:09.279360Z", "end_time": "2018-06-16T23:07:09.285135Z"}, "trusted": true}, "cell_type": "code", "source": "# given a list of ids we can \"look up\" the embedding corresponing to each id\n# can you see that some vectors are the same?\na = torch.LongTensor([[1,0,1,4,5,1]])\nembed(a)", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "tensor([[[ 0.1271, -0.2549,  0.3582],\n         [-0.0596,  0.6845,  0.8395],\n         [ 0.1271, -0.2549,  0.3582],\n         [ 1.0334,  1.7368,  0.4366],\n         [-0.8050,  0.0520,  0.0131],\n         [ 0.1271, -0.2549,  0.3582]]])"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Matrix Factorization Model"}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:16:34.465938Z", "end_time": "2018-06-16T23:16:34.470237Z"}, "trusted": true}, "cell_type": "code", "source": "class MF(nn.Module):\n    def __init__(self, num_users, num_items, emb_size=100):\n        super(MF, self).__init__()\n        self.user_emb = nn.Embedding(num_users, emb_size)\n        self.item_emb = nn.Embedding(num_items, emb_size)\n        # Initialize weights (replace random values)\n        self.user_emb.weight.data.uniform_(0,0.05)\n        self.item_emb.weight.data.uniform_(0,0.05)\n    \n    def forward(self, u, v):\n        u = self.user_emb(u)\n        v = self.item_emb(v)\n        return (u*v).sum(1)", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Training Model"}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:19:20.087370Z", "end_time": "2018-06-16T23:19:20.093432Z"}, "trusted": true}, "cell_type": "code", "source": "num_users = len(df_train.userId.unique())\nnum_items = len(df_train.movieId.unique())\nprint(num_users, num_items)", "execution_count": 30, "outputs": [{"output_type": "stream", "text": "671 8442\n", "name": "stdout"}]}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:13.811278Z", "end_time": "2018-06-16T23:37:13.833497Z"}, "trusted": true}, "cell_type": "code", "source": "model = MF(num_users, num_items, emb_size=100).cuda()", "execution_count": 51, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:03.087700Z", "end_time": "2018-06-16T23:37:03.092777Z"}, "trusted": true}, "cell_type": "code", "source": "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n    # Filter for parameters that require training\n    parameters = filter(lambda p: p.requires_grad, model.parameters())\n    optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n    model.train()\n    users = torch.LongTensor(df_train.userId.values).cuda()\n    items = torch.LongTensor(df_train.movieId.values).cuda()\n    ratings = torch.FloatTensor(df_train.rating.values).cuda()\n    if unsqueeze:\n            ratings = ratings.unsqueeze(1).cuda() # Unsqueeze makes a 1d object 2d\n    for i in tnrange(epochs):\n        y_hat = model(users, items)\n        loss = F.mse_loss(y_hat, ratings)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        tqdm.write(f'Train loss: {loss.item():{.4}}')\n        \n    test_loss(model, unsqueeze)", "execution_count": 49, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:06.373337Z", "end_time": "2018-06-16T23:37:06.379925Z"}, "trusted": true}, "cell_type": "code", "source": "def test_loss(model, unsqueeze=False):\n    model.eval()\n    users = torch.LongTensor(df_val.userId.values).cuda()\n    items = torch.LongTensor(df_val.movieId.values).cuda()\n    ratings = torch.FloatTensor(df_val.rating.values).cuda()\n    if unsqueeze:\n        ratings = ratings.unsqueeze(1)\n    y_hat = model(users, items)\n    loss = F.mse_loss(y_hat, ratings)\n    print(f'Test loss {loss.item():{.4}}')", "execution_count": 50, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:33.759086Z", "end_time": "2018-06-16T23:37:33.934095Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=10, lr=0.1)", "execution_count": 54, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5ef3f86d74614738bb6d2041a5ef320e"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 13.23\nTrain loss: 5.122\nTrain loss: 2.376\nTrain loss: 3.449\nTrain loss: 0.9087\nTrain loss: 1.808\nTrain loss: 2.749\nTrain loss: 2.279\nTrain loss: 1.157\nTrain loss: 0.9222\n\nTest loss 1.947\n", "name": "stdout"}]}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:39.910970Z", "end_time": "2018-06-16T23:37:40.152323Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=15, lr=0.01)", "execution_count": 55, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b63b6887d4c3492d8b270885833a04d2"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 1.704\nTrain loss: 1.051\nTrain loss: 0.7492\nTrain loss: 0.6943\nTrain loss: 0.7594\nTrain loss: 0.8401\nTrain loss: 0.8825\nTrain loss: 0.8762\nTrain loss: 0.8341\nTrain loss: 0.777\nTrain loss: 0.7246\nTrain loss: 0.6898\nTrain loss: 0.6766\nTrain loss: 0.6805\nTrain loss: 0.692\n\nTest loss 0.8934\n", "name": "stdout"}]}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:45.146999Z", "end_time": "2018-06-16T23:37:45.396874Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=15, lr=0.001)", "execution_count": 56, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "907d1b94b2db44fbaf7a4483854ae3ed"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 0.7008\nTrain loss: 0.6845\nTrain loss: 0.6711\nTrain loss: 0.6605\nTrain loss: 0.6526\nTrain loss: 0.6468\nTrain loss: 0.6429\nTrain loss: 0.6402\nTrain loss: 0.6385\nTrain loss: 0.6373\nTrain loss: 0.6364\nTrain loss: 0.6357\nTrain loss: 0.6349\nTrain loss: 0.6341\nTrain loss: 0.6333\n\nTest loss 0.8301\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Matrix Factorization with Bias"}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:50.348450Z", "end_time": "2018-06-16T23:37:50.353757Z"}, "trusted": true}, "cell_type": "code", "source": "class MF_bias(nn.Module):\n    def __init__(self, num_users, num_items, emb_size=100):\n        super(MF_bias, self).__init__()\n        self.user_emb = nn.Embedding(num_users, emb_size)\n        self.user_bias = nn.Embedding(num_users, 1)\n        self.item_emb = nn.Embedding(num_items, emb_size)\n        self.item_bias = nn.Embedding(num_items, 1)\n        # init \n        self.user_emb.weight.data.uniform_(0,0.05)\n        self.item_emb.weight.data.uniform_(0,0.05)\n        self.user_bias.weight.data.uniform_(-0.01,0.01)\n        self.item_bias.weight.data.uniform_(-0.01,0.01)\n        \n    def forward(self, u, v):\n        U = self.user_emb(u)\n        V = self.item_emb(v)\n        b_u = self.user_bias(u).squeeze()\n        b_v = self.item_bias(v).squeeze()\n        return (U*V).sum(1) +  b_u  + b_v", "execution_count": 57, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:53.751369Z", "end_time": "2018-06-16T23:37:53.772828Z"}, "trusted": true}, "cell_type": "code", "source": "model = MF_bias(num_users, num_items, emb_size=100).cuda()", "execution_count": 58, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:54.642389Z", "end_time": "2018-06-16T23:37:54.846824Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=10, lr=0.1, wd=1e-5)", "execution_count": 59, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6eb26acf24a748f38526847c8e385926"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 13.23\nTrain loss: 4.372\nTrain loss: 3.481\nTrain loss: 2.467\nTrain loss: 0.7877\nTrain loss: 1.814\nTrain loss: 2.519\nTrain loss: 2.137\nTrain loss: 1.27\nTrain loss: 0.9019\n\nTest loss 1.538\n", "name": "stdout"}]}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:37:58.422422Z", "end_time": "2018-06-16T23:37:58.621813Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=10, lr=0.01, wd=1e-5)", "execution_count": 60, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "12c619a517044bcc8debb71d5874acdf"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 1.283\nTrain loss: 0.8582\nTrain loss: 0.6944\nTrain loss: 0.6954\nTrain loss: 0.7549\nTrain loss: 0.8005\nTrain loss: 0.8074\nTrain loss: 0.781\nTrain loss: 0.7383\nTrain loss: 0.6966\n\nTest loss 0.8234\n", "name": "stdout"}]}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:38:03.061394Z", "end_time": "2018-06-16T23:38:03.246793Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=10, lr=0.001, wd=1e-5)", "execution_count": 61, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "f2ee9d86c5814dd6986624ed1fd7c4bb"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 0.6681\nTrain loss: 0.6601\nTrain loss: 0.6533\nTrain loss: 0.6479\nTrain loss: 0.6436\nTrain loss: 0.6402\nTrain loss: 0.6375\nTrain loss: 0.6354\nTrain loss: 0.6337\nTrain loss: 0.6323\n\nTest loss 0.8098\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Neural Network Model"}, {"metadata": {}, "cell_type": "markdown", "source": "The main difference between MF based collaborative filtering and NN based is that there is no matrix multiplication in  the later one, implying the embedding dimension can be different for users and items. Also, regularization can help get better results on the test set."}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:38:07.459747Z", "end_time": "2018-06-16T23:38:07.465122Z"}, "trusted": true}, "cell_type": "code", "source": "class CollabFNet(nn.Module):\n    def __init__(self, num_users, num_items, user_emb_size=100,\n                 item_emb_size=100, n_hidden=10):\n        super(CollabFNet, self).__init__()\n        self.user_emb = nn.Embedding(num_users, user_emb_size)\n        self.item_emb = nn.Embedding(num_items, item_emb_size)\n        self.lin1 = nn.Linear(user_emb_size + item_emb_size,\n                              n_hidden)\n        self.lin2 = nn.Linear(n_hidden, 1)\n        self.drop1 = nn.Dropout(0.1)\n        self.drop2 = nn.Dropout(0.0)\n        \n    def forward(self, u, v):\n        U = self.user_emb(u)\n        V = self.item_emb(v)\n        x = F.relu(torch.cat([U, V], dim=1))\n        x = self.drop1(x)\n        x = F.relu(self.lin1(x))\n        x = self.drop2(x)\n        x = self.lin2(x)\n        return x", "execution_count": 62, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:38:13.613500Z", "end_time": "2018-06-16T23:38:13.626740Z"}, "trusted": true}, "cell_type": "code", "source": "model = CollabFNet(num_users, num_items, user_emb_size=80, item_emb_size=100).cuda()", "execution_count": 63, "outputs": []}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:38:14.507796Z", "end_time": "2018-06-16T23:38:15.048114Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=20, lr=0.01, wd=1e-5, unsqueeze=True)", "execution_count": 64, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "9cfc50af61484f39809fa39e19f7d3f0"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 12.88\nTrain loss: 7.583\nTrain loss: 3.116\nTrain loss: 1.323\nTrain loss: 2.391\nTrain loss: 3.821\nTrain loss: 3.826\nTrain loss: 2.898\nTrain loss: 1.887\nTrain loss: 1.305\nTrain loss: 1.242\nTrain loss: 1.508\nTrain loss: 1.844\nTrain loss: 2.064\nTrain loss: 2.094\nTrain loss: 1.93\nTrain loss: 1.66\nTrain loss: 1.377\nTrain loss: 1.161\nTrain loss: 1.069\n\nTest loss 1.074\n", "name": "stdout"}]}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:38:38.173174Z", "end_time": "2018-06-16T23:38:38.801742Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=20, lr=0.01, wd=1e-5, unsqueeze=True)", "execution_count": 65, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "767af770712f4df89eec4e9f3b50de4f"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 1.098\nTrain loss: 1.854\nTrain loss: 1.113\nTrain loss: 1.144\nTrain loss: 1.398\nTrain loss: 1.178\nTrain loss: 0.9652\nTrain loss: 1.007\nTrain loss: 1.126\nTrain loss: 1.116\nTrain loss: 0.9961\nTrain loss: 0.8988\nTrain loss: 0.9075\nTrain loss: 0.9698\nTrain loss: 0.9752\nTrain loss: 0.9061\nTrain loss: 0.8483\nTrain loss: 0.8636\nTrain loss: 0.8946\nTrain loss: 0.8885\n\nTest loss 0.8694\n", "name": "stdout"}]}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:38:43.773143Z", "end_time": "2018-06-16T23:38:44.322045Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=20, lr=0.001, wd=1e-5, unsqueeze=True)", "execution_count": 66, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "aa138f0e5d0f40a0a99955dada6f7ad6"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 0.8488\nTrain loss: 0.8254\nTrain loss: 0.8249\nTrain loss: 0.8314\nTrain loss: 0.8306\nTrain loss: 0.8251\nTrain loss: 0.8192\nTrain loss: 0.8172\nTrain loss: 0.8185\nTrain loss: 0.821\nTrain loss: 0.8224\nTrain loss: 0.8192\nTrain loss: 0.8152\nTrain loss: 0.8165\nTrain loss: 0.8126\nTrain loss: 0.8137\nTrain loss: 0.8124\nTrain loss: 0.8102\nTrain loss: 0.8106\nTrain loss: 0.8117\n\nTest loss 0.8308\n", "name": "stdout"}]}, {"metadata": {"ExecuteTime": {"start_time": "2018-06-16T23:39:01.361819Z", "end_time": "2018-06-16T23:39:01.887237Z"}, "trusted": true}, "cell_type": "code", "source": "train_epocs(model, epochs=20, lr=0.001, wd=1e-5, unsqueeze=True)", "execution_count": 67, "outputs": [{"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "8672e0eb80a74a58b699de007de76358"}}, "metadata": {}}, {"output_type": "stream", "text": "Train loss: 0.8092\nTrain loss: 0.8157\nTrain loss: 0.8089\nTrain loss: 0.8098\nTrain loss: 0.8107\nTrain loss: 0.8096\nTrain loss: 0.8037\nTrain loss: 0.8072\nTrain loss: 0.8063\nTrain loss: 0.8064\nTrain loss: 0.8059\nTrain loss: 0.8006\nTrain loss: 0.8029\nTrain loss: 0.8029\nTrain loss: 0.8013\nTrain loss: 0.8033\nTrain loss: 0.8005\nTrain loss: 0.8005\nTrain loss: 0.8\nTrain loss: 0.7986\n\nTest loss 0.8236\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "conda-env-pytorch_p36-py", "display_name": "Python [conda env:pytorch_p36]", "language": "python"}, "language_info": {"name": "python", "version": "3.6.5", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}